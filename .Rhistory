text(pathways.data$genes+0.65, bp+0.6, pathways.data$pval, cex = 0.85, pos = 1)
dev.off()
tiff('/media/miles/Backup/miles_lappy/Data/Phd/Chapter_Phenomescan/PLoS_Genetics/Fig5_150925.tiff',
compression = 'lzw', res = 300, width = 2400, height = 900)
par(mai=c(1,2.5,0.5,0.5))
bp <- barplot(pathways.data$genes, horiz = T, names.arg = pathways.data$pathway, xlab = 'Number of genes', xlim = c(0,5.5),
col = c('darkred', rep('cadetblue', 4)), las = 1, xpd = T)
text(pathways.data$genes+0.65, bp+0.6, pathways.data$pval, cex = 0.85, pos = 1)
dev.off()
tiff('/media/miles/Backup/miles_lappy/Data/Phd/Chapter_Phenomescan/PLoS_Genetics/Fig5_150925.tiff',
compression = 'lzw', res = 300, width = 2400, height = 900)
par(mai=c(1,2.5,0.25,0.25))
bp <- barplot(pathways.data$genes, horiz = T, names.arg = pathways.data$pathway, xlab = 'Number of genes', xlim = c(0,5.5),
col = c('darkred', rep('cadetblue', 4)), las = 1, xpd = T)
text(pathways.data$genes+0.65, bp+0.6, pathways.data$pval, cex = 0.85, pos = 1)
dev.off()
tiff('/media/miles/Backup/miles_lappy/Data/Phd/Chapter_Phenomescan/PLoS_Genetics/Fig5_150925.tiff',
compression = 'lzw', res = 300, width = 2400, height = 900)
par(mai=c(0.85,2.5,0.15,0.15))
bp <- barplot(pathways.data$genes, horiz = T, names.arg = pathways.data$pathway, xlab = 'Number of genes', xlim = c(0,5.5),
col = c('darkred', rep('cadetblue', 4)), las = 1, xpd = T)
text(pathways.data$genes+0.65, bp+0.6, pathways.data$pval, cex = 0.85, pos = 1)
dev.off()
tiff('/media/miles/Backup/miles_lappy/Data/Phd/Chapter_Phenomescan/PLoS_Genetics/Fig5_150925.tiff',
compression = 'lzw', res = 300, width = 2400, height = 900)
par(mai=c(0.85,2.5,0.15,0.1))
bp <- barplot(pathways.data$genes, horiz = T, names.arg = pathways.data$pathway, xlab = 'Number of genes', xlim = c(0,5.5),
col = c('darkred', rep('cadetblue', 4)), las = 1, xpd = T)
text(pathways.data$genes+0.65, bp+0.6, pathways.data$pval, cex = 0.85, pos = 1)
dev.off()
tiff('/media/miles/Backup/miles_lappy/Data/Phd/Chapter_Phenomescan/PLoS_Genetics/Fig5_150925.tiff',
compression = 'lzw', res = 300, width = 2400, height = 900)
par(mai=c(0.85,2.5,0.15,0.1))
bp <- barplot(pathways.data$genes, horiz = T, names.arg = pathways.data$pathway, xlab = 'Number of genes', xlim = c(0,5.5),
col = c('darkred', rep('cadetblue', 4)), las = 1, xpd = T)
text(pathways.data$genes+0.65, bp+0.5, pathways.data$pval, cex = 0.9, pos = 1)
dev.off()
tiff('/media/miles/Backup/miles_lappy/Data/Phd/Chapter_Phenomescan/PLoS_Genetics/Fig5_150925.tiff',
compression = 'lzw', res = 300, width = 2400, height = 900)
par(mai=c(0.85,2.5,0.15,0.1))
bp <- barplot(pathways.data$genes, horiz = T, names.arg = pathways.data$pathway, xlab = 'Number of genes', xlim = c(0,6),
col = c('darkred', rep('cadetblue', 4)), las = 1, xpd = T)
text(pathways.data$genes+0.65, bp+0.5, pathways.data$pval, cex = 0.9, pos = 1)
dev.off()
tiff('/media/miles/Backup/miles_lappy/Data/Phd/Chapter_Phenomescan/PLoS_Genetics/Fig5_150925.tiff',
compression = 'lzw', res = 300, width = 2400, height = 900)
par(mai=c(0.85,2.5,0.15,0.1))
bp <- barplot(pathways.data$genes, horiz = T, names.arg = pathways.data$pathway, xlab = 'Number of genes', xlim = c(0,5.5),
col = c('darkred', rep('cadetblue', 4)), las = 1, xpd = T)
text(pathways.data$genes+0.65, bp+0.5, pathways.data$pval, cex = 0.95, pos = 1)
dev.off()
tiff('/media/miles/Backup/miles_lappy/Data/Phd/Chapter_Phenomescan/PLoS_Genetics/Fig5_150925.tiff',
compression = 'lzw', res = 300, width = 2400, height = 900)
par(mai=c(0.85,2.5,0.15,0.1))
bp <- barplot(pathways.data$genes, horiz = T, names.arg = pathways.data$pathway, xlab = 'Number of genes', xlim = c(0,5.5),
col = c('darkred', rep('cadetblue', 4)), las = 1, xpd = T)
text(pathways.data$genes+0.65, bp+0.45, pathways.data$pval, cex = 0.95, pos = 1)
dev.off()
library("BiocInstaller", lib.loc="/usr/local/lib/R/site-library")
biocLite('minfi')
biocLite('affy')
biocLite('VariantAnnotation')
biocLite('Biobase')
biocLite('ggbio')
biocLite('GenomicRanges')
require(minfi)
estimateCellCounts()
estimateCellCounts
estimateCellCounts()
?estimateCellCounts()
platform <- "450k"
referencePkg <- sprintf("FlowSorted.%s.%s", compositeCellType,
platform)
compositeCellType = "Blood"
cellTypes = c("CD8T",
"CD4T", "NK", "Bcell", "Mono", "Gran")
returnAll = FALSE
meanPlot = FALSE
verbose = TRUE
platform <- "450k"
referencePkg <- sprintf("FlowSorted.%s.%s", compositeCellType,
platform)
subverbose <- max(as.integer(verbose) - 1L, 0L)
if (!require(referencePkg, character.only = TRUE))
stop(sprintf("Could not find reference data package for compositeCellType '%s' and platform '%s' (inferred package name is '%s')",
compositeCellType, platform, referencePkg))
data(list = referencePkg)
referenceRGset <- get(referencePkg)
referencePkg
referenceRGset
if (!"CellType" %in% names(pData(referenceRGset)))
stop(sprintf("the reference sorted dataset (in this case '%s') needs to have a phenoData column called 'CellType'"),
names(referencePkg))
if (sum(colnames(rgSet) %in% colnames(referenceRGset)) >
0)
stop("the sample/column names in the user set must not be in the reference data ")
if (!all(cellTypes %in% referenceRGset$CellType))
stop(sprintf("all elements of argument 'cellTypes' needs to be part of the reference phenoData columns 'CellType' (containg the following elements: '%s')",
paste(unique(referenceRGset$cellType), collapse = "', '")))
if (length(unique(cellTypes)) < 2)
stop("At least 2 cell types must be provided.")
if (verbose)
cat("[estimateCellCounts] Combining user data with reference (flow sorted) data.\n")
?pickCompProbes
??pickCompProbes
.libPaths()
help("Startup")
.libPaths()
.libPaths()
.libPaths()
.Library
.Library.site
library("BiocInstaller", lib.loc="/home/R/linux-library/main/site-library")
biocLite()
biocLite('missMethyl')
.libPaths()
library("BiocInstaller", lib.loc="/home/R/linux-library/main/site-library")
biocLite()
.libPaths()
.libPaths()
install.packages("dygraphs")
install.packages("rcrossref")
install.packages("rorcid")
devtools::install_github("ropensci/rorcid")
library(twitteR)
library(rorcid)
library(rcrossref)
tweetAuthor = function(orcid=NULL, hashtag=NULL) {
person = as.orcid(orcid)
firstName = person[[1]]$”orcid-bio”$`personal-details`$`given-names`$value
surname = person[[1]]$”orcid-bio”$`personal-details`$`family-name`$value
orcidURL = person[[1]]$”orcid-identifier”$uri
tweet(
paste(firstName, ” “, surname, ” orcid:”,
orcid, ” “, orcidURL, ” #”, hashtag, sep=””)
)
}
tweetPaper = function(doi=NULL, hashtag=NULL) {
info = cr_cn(dois=doi, format=”citeproc-json”)
tweet(
paste(
info$author[[1]]$family, ” et al. “”,
substr(info$title, 0, 60), “…” “,
“http://dx.doi.org/”, info$DOI, ” #”, hashtag, sep=””
)
)
}
tweetAuthor = function(orcid=NULL, hashtag=NULL) {
person = as.orcid(orcid)
firstName = person[[1]]$”orcid-bio”$`personal-details`$`given-names`$value
surname = person[[1]]$”orcid-bio”$`personal-details`$`family-name`$value
orcidURL = person[[1]]$”orcid-identifier”$uri
tweet(
paste(firstName, ” “, surname, ” orcid:”,
orcid, ” “, orcidURL, ” #”, hashtag, sep=””)
)
}
tweetAuthor = function(orcid=NULL, hashtag=NULL) {
person = as.orcid(orcid)
firstName = person[[1]]$"orcid-bio"$`personal-details`$`given-names`$value
surname = person[[1]]$"orcid-bio"$`personal-details`$`family-name`$value
orcidURL = person[[1]]$"orcid-identifier"$uri
tweet(
paste(firstName, " ", surname, " orcid:",
orcid, " ", orcidURL, " #", hashtag, sep="")
)
}
tweetAuthor()
?setup_twitter_oauth
API_KEY <- "hIhVWcdgJwkhKShas3DQBYugE"
API_KEY <- "hIhVWcdgJwkhKShas3DQBYugE"
API_SECRET <- "0LrqBVgQJFTZbTY7SbVtmp04hfgMKppiibbF18sd5P5wVpzYPR"
setup_twitter_oauth(API_KEY, API_SECRET)
tweetPaper = function(doi=NULL, hashtag=NULL) {
info = cr_cn(dois=doi, format=”citeproc-json”)
tweet(
paste(
info$author[[1]]$family, " et al. ",
substr(info$title, 0, 60), "...",
"http://dx.doi.org/", info$DOI, " #", hashtag, sep=""
)
)
}
tweetPaper = function(doi=NULL, hashtag=NULL) {
info = cr_cn(dois=doi, format="citeproc-json")
tweet(
paste(
info$author[[1]]$family, " et al. ",
substr(info$title, 0, 60), "...",
"http://dx.doi.org/", info$DOI, " #", hashtag, sep=""
)
)
}
tweetPaper = function(doi=NULL, hashtag=NULL, at=NULL) {
info = cr_cn(dois=doi, format="citeproc-json")
tweet(
paste(
info$author[[1]]$family, " et al. ",
substr(info$title, 0, 60), "...",
"http://dx.doi.org/", info$DOI, " #", hashtag, " @", at, sep=""
)
)
}
tweetPaper(doi = "10.2307/41937738", hashtag = "testing", at = "Ray_Blick")
tweetPaper(doi = "10.1111/j.1600-0706.2012.20870.x", hashtag = "testing", at = "Ray_Blick")
doi = "10.1111/j.1600-0706.2012.20870.x"
hashtag = "testing"
at = "Ray_Blick"
info = cr_cn(dois=doi, format="citeproc-json")
info
paste(
info$author[[1]]$family, " et al. ",
substr(info$title, 0, 60), "...",
"http://dx.doi.org/", info$DOI, " #", hashtag, " @", at, sep=""
)
test <- paste(
info$author[[1]]$family, " et al. ",
substr(info$title, 0, 60), "...",
"http://dx.doi.org/", info$DOI, " #", hashtag, " @", at, sep=""
)
length(test)
test
?length
install.packages("nchar")
nchar(test)
paste(
info$author[[1]]$family, " et al. ",
substr(info$title, 0, 54), "...",
"http://dx.doi.org/", info$DOI, " #", hashtag, " @", at, sep=""
)
tweetPaper = function(doi=NULL, hashtag=NULL, at=NULL) {
info = cr_cn(dois=doi, format="citeproc-json")
tweet(
paste(
info$author[[1]]$family, " et al. ",
substr(info$title, 0, 54), "...",
"http://dx.doi.org/", info$DOI, " #", hashtag, " @", at, sep=""
)
)
}
tweetPaper(doi = "10.1111/j.1600-0706.2012.20870.x", hashtag = "testing", at = "Ray_Blick")
library(twitteR)
library(rorcid)
library(rcrossref)
API_KEY <- "hIhVWcdgJwkhKShas3DQBYugE"
API_SECRET <- "0LrqBVgQJFTZbTY7SbVtmp04hfgMKppiibbF18sd5P5wVpzYPR"
setup_twitter_oauth(API_KEY, API_SECRET)
tweetAuthor = function(orcid=NULL, hashtag=NULL) {
person = as.orcid(orcid)
firstName = person[[1]]$"orcid-bio"$`personal-details`$`given-names`$value
surname = person[[1]]$"orcid-bio"$`personal-details`$`family-name`$value
orcidURL = person[[1]]$"orcid-identifier"$uri
tweet(
paste(firstName, " ", surname, " orcid:",
orcid, " ", orcidURL, " #", hashtag, sep="")
)
}
tweetPaper = function(doi=NULL, hashtag=NULL, at=NULL) {
info = cr_cn(dois=doi, format="citeproc-json")
tweet(
paste(
info$author[[1]]$family, " et al. ",
substr(info$title, 0, 54), "...",
"http://dx.doi.org/", info$DOI, " #", hashtag, " @", at, sep=""
)
)
}
tweetPaper(doi = "10.1016/j.cub.2006.05.056", hashtag = "B32015")
tweetPaper(doi = "doi:10.1016/j.cell.2015.04.041", hashtag = "B32015", at = "IFE_QUT")
tweetPaper(doi = "10.1038/nmeth.3258", hashtag = "B32015", at = "IFE_QUT")
tweetPaper(doi = "10.1073/pnas.1508380112", hashtag = "B32015", at = "IFE_QUT")
tweetPaper(doi = "10.1038/nmeth.f.301", hashtag = "B32015", at = "IFE_QUT")
tweetPaper(doi = "10.1371/journal.pcbi.1004075", hashtag = "B32015", at = "IFE_QUT")
tweetPaper(doi = "10.1093/bioinformatics/btn482", hashtag = "B32015", at = "IFE_QUT")
library(twitteR)
library(rorcid)
library(rcrossref)
API_KEY <- "hIhVWcdgJwkhKShas3DQBYugE"
API_SECRET <- "0LrqBVgQJFTZbTY7SbVtmp04hfgMKppiibbF18sd5P5wVpzYPR"
setup_twitter_oauth(API_KEY, API_SECRET)
tweetAuthor = function(orcid=NULL, hashtag=NULL) {
person = as.orcid(orcid)
firstName = person[[1]]$"orcid-bio"$`personal-details`$`given-names`$value
surname = person[[1]]$"orcid-bio"$`personal-details`$`family-name`$value
orcidURL = person[[1]]$"orcid-identifier"$uri
tweet(
paste(firstName, " ", surname, " orcid:",
orcid, " ", orcidURL, " #", hashtag, sep="")
)
}
tweetPaper = function(doi=NULL, hashtag=NULL, at=NULL) {
info = cr_cn(dois=doi, format="citeproc-json")
tweet(
paste(
info$author[[1]]$family, " et al. ",
substr(info$title, 0, 54), "...",
"http://dx.doi.org/", info$DOI, " #", hashtag, " @", at, sep=""
)
)
}
tweetPaper(doi = "10.1093/bioinformatics/btn482", hashtag = "B32015", at = "IFE_QUT")
tweetPaper(doi = "10.1093/bioinformatics/btq051", hashtag = "B32015", at = "IFE_QUT")
B32015 <- searchTwitter("#B32015", n=60, since='2007-10-30')
B32015 <- searchTwitter("#B32015", n=250, since='2007-10-30')
B32015
grep('miles', B32015)
mapply(grep, 'miles', B32015)
lapply(B32015, function(x) grep('miles',x))
as.character(B32015)
as.character(B32015[])
B32015
as.character(B32015)
unlist(B32015)
grep('miles', unlist(B32015))
unlist(B32015)
B32015
unlist(B32015, recursive = T)
str(B32015)
as.list(B32015)
unlist(as.list(B32015))
library(twitteR)
library(rorcid)
library(rcrossref)
API_KEY <- "hIhVWcdgJwkhKShas3DQBYugE"
API_SECRET <- "0LrqBVgQJFTZbTY7SbVtmp04hfgMKppiibbF18sd5P5wVpzYPR"
setup_twitter_oauth(API_KEY, API_SECRET)
tweetAuthor = function(orcid=NULL, hashtag=NULL) {
person = as.orcid(orcid)
firstName = person[[1]]$"orcid-bio"$`personal-details`$`given-names`$value
surname = person[[1]]$"orcid-bio"$`personal-details`$`family-name`$value
orcidURL = person[[1]]$"orcid-identifier"$uri
tweet(
paste(firstName, " ", surname, " orcid:",
orcid, " ", orcidURL, " #", hashtag, sep="")
)
}
tweetPaper = function(doi=NULL, hashtag=NULL, at=NULL) {
info = cr_cn(dois=doi, format="citeproc-json")
tweet(
paste(
info$author[[1]]$family, " et al. ",
substr(info$title, 0, 54), "...",
"http://dx.doi.org/", info$DOI, " #", hashtag, " @", at, sep=""
)
)
}
B32015 <- searchTwitter("#B32015", n=250, since='2007-10-30')
str(B32015)
head(B32015)
B32015[1]
B32015[[1]]
class(B32015)
as.vector(B32015)
test <- as.vector(B32015)
str(test)
B32015$text
head(str(B32015))
b32015_text <- sapply(b32015_text, function(x) x$getText())
b32015_text <- sapply(B32015_text, function(x) x$getText())
b32015_text <- sapply(B32015, function(x) x$getText())
lapply(b32015_text, function(x) grep('miles',x))
unlist(b32015_text)
grep('miles', unlist(b32015_text))
grep('miles*', unlist(b32015_text))
b3_corpus <- Corpus(VectorSource(b32015_text))
install.packages("wordcloud")
install.packages("tm")
library("wordcloud")
library("tm")
b3_corpus <- Corpus(VectorSource(b32015_text))
b3_corpus
b3_corpus <- tm_map(b3_corpus, content_transformer(tolower))
b3_corpus <- tm_map(b3_corpus, removePunctuation)
b3_corpus <- tm_map(b3_corpus, function(x)removeWords(x,stopwords()))
wordcloud(r_stats_text_corpus)
wordcloud(b3_corpus)
RR <- searchTwitter("#reproducibleresearch", n=250, since='2007-10-30')
RR <- searchTwitter("#reproducibleresearch", n=50, since='2007-10-30')
RR <- searchTwitter("#ReproducibleResearch", n=50, since='2007-10-30')
OS <- searchTwitter("#OpenScience", n=500)
OS <- searchTwitter("#OpenScience", n=5000)
OS_text <- sapply(OS, function(x) x$getText())
OS_corpus <- Corpus(VectorSource(OS_text))
OS_corpus <- tm_map(OS_corpus, content_transformer(tolower))
OS_corpus <- tm_map(OS_corpus, removePunctuation)
OS_corpus <- tm_map(OS_corpus, function(x)removeWords(x,stopwords()))
wordcloud(OS_corpus)
RR <- searchTwitter("#ReproducibleResearch", n=500)
RR <- searchTwitter("#Reproducible_Research", n=500)
RR <- searchTwitter("#ReproducibleScience", n=500)
B32015 <- searchTwitter("#B32015", n=250)
b32015_text <- sapply(B32015, function(x) x$getText())
# lapply(b32015_text, function(x) grep('miles',x))
b3_corpus <- Corpus(VectorSource(b32015_text))
b3_corpus <- tm_map(b3_corpus, content_transformer(tolower))
b3_corpus <- tm_map(b3_corpus, removePunctuation)
b3_corpus <- tm_map(b3_corpus, function(x)removeWords(x,stopwords()))
wordcloud(b3_corpus)
wordcloud(b3_corpus)
?wordcloud
tweetPaper(doi = "10.1073/pnas.1003379107", hashtag = "B32015", at = "IFE_QUT")
mt <- searchTwitter("#mitochondria", n=2000)
mt_text <- sapply(mt, function(x) x$getText())
mt_text <- sapply(mt, function(x) x$getText())
mt_corpus <- Corpus(VectorSource(mt_text))
mt_corpus <- tm_map(mt_corpus, content_transformer(tolower))
mt_corpus <- tm_map(mt_corpus, removePunctuation)
mt_corpus <- tm_map(mt_corpus, function(x)removeWords(x,stopwords()))
wordcloud(mt_corpus)
mt_text <- sapply(mt, function(x) x$getText())
mt_corpus <- Corpus(VectorSource(mt_text))
mt_corpus <- tm_map(mt_corpus, content_transformer(tolower))
mt
mt_corpus <- Corpus(VectorSource(mt_text))
mt_corpus
OS_text <- sapply(OS, function(x) x$getText())
OS_corpus <- Corpus(VectorSource(OS_text))
OS_corpus <- tm_map(OS_corpus, content_transformer(tolower))
OS_corpus <- tm_map(OS_corpus, removePunctuation)
OS_corpus <- tm_map(OS_corpus, function(x)removeWords(x,stopwords()))
mt_text <- sapply(mt, function(x) x$getText())
mt_corpus <- Corpus(VectorSource(mt_text))
mt_corpus <- tm_map(mt_corpus, content_transformer(tolower))
mt_corpus <- tm_map(mt_corpus, removePunctuation)
mt_corpus <- tm_map(mt_corpus, function(x)removeWords(x,stopwords()))
wordcloud(mt_corpus)
tm_map()
?tm_map()
VectorSource(mt_text)
content_transformer(tolower)
mt <- searchTwitter("#mitochondrion", n=2000)
mt <- searchTwitter("#mitochondria", n=2000)
mt_text <- sapply(mt, function(x) x$getText())
mt_corpus <- Corpus(VectorSource(mt_text))
mt_corpus <- tm_map(mt_corpus, content_transformer(tolower))
mt_corpus <- tm_map(mt_corpus, removePunctuation)
mt_corpus <- tm_map(mt_corpus, function(x)removeWords(x,stopwords()))
wordcloud(mt_corpus)
mt_corpus
mt <- searchTwitter("#mtDNA", n=2000)
mt_text <- sapply(mt, function(x) x$getText())
mt_corpus <- Corpus(VectorSource(mt_text))
mt_corpus <- tm_map(mt_corpus, content_transformer(tolower))
mt_corpus <- tm_map(mt_corpus, removePunctuation)
mt_corpus <- tm_map(mt_corpus, function(x)removeWords(x,stopwords()))
wordcloud(mt_corpus)
mt <- searchTwitter("#mitochondrial", n=2000)
mt_text <- sapply(mt, function(x) x$getText())
mt_corpus <- Corpus(VectorSource(mt_text))
mt_corpus <- tm_map(mt_corpus, content_transformer(tolower))
mt_corpus <- tm_map(mt_corpus, removePunctuation)
mt_corpus <- tm_map(mt_corpus, function(x)removeWords(x,stopwords()))
wordcloud(mt_corpus)
mt <- searchTwitter("#mitochondria", n=200)
mt_text <- sapply(mt, function(x) x$getText())
mt_corpus <- Corpus(VectorSource(mt_text))
mt_corpus <- tm_map(mt_corpus, content_transformer(tolower))
mt_text
mt <- searchTwitter("#illumina", n=200)
mt_text <- sapply(mt, function(x) x$getText())
mt_corpus <- Corpus(VectorSource(mt_text))
mt_corpus <- tm_map(mt_corpus, content_transformer(tolower))
mt_corpus <- tm_map(mt_corpus, removePunctuation)
mt_corpus <- tm_map(mt_corpus, function(x)removeWords(x,stopwords()))
wordcloud(mt_corpus)
mt <- searchTwitter("#bioinformatics", n=200)
mt_text <- sapply(mt, function(x) x$getText())
mt_corpus <- Corpus(VectorSource(mt_text))
mt_corpus <- tm_map(mt_corpus, content_transformer(tolower))
mt_corpus <- tm_map(mt_corpus, removePunctuation)
mt_corpus <- tm_map(mt_corpus, function(x)removeWords(x,stopwords()))
wordcloud(mt_corpus)
mt <- searchTwitter("#bioinformatics", n=2000)
mt_text <- sapply(mt, function(x) x$getText())
mt_corpus <- Corpus(VectorSource(mt_text))
mt_corpus <- tm_map(mt_corpus, content_transformer(tolower))
mt_corpus <- tm_map(mt_corpus, removePunctuation)
mt_corpus <- tm_map(mt_corpus, function(x)removeWords(x,stopwords()))
wordcloud(mt_corpus)
warnings()
nihs2010 <- read.csv('/media/miles/Backup/miles_lappy/Data/Phd/UUID_Miles/NIHS2010_phenodata.csv', head = T)
nihs2000 <- read.csv('/media/miles/Backup/miles_lappy/Data/Phd/UUID_Miles/NIHS2000_phenodata.csv', head = T)
head(nihs2000)
nihs2000$HYPTEN
table(nihs2000$HYPTEN)
table(nihs2000$SBP >= 140)
table(nihs2000$SBP >= 140 & nihs2000$DBP >= 90)
table(nihs2000$SBP > 140 & nihs2000$DBP > 90)
table(nihs2010$HYPTEN)
45+543
table(nihs2010$SBP > 140 & nihs2010$DBP > 90)
142/622
library("BiocInstaller", lib.loc="/home/R/linux-library/main/site-library")
biocLite('rhdf5')
install.packages(c("multcomp", "mvtnorm", "pbkrtest", "RcppEigen", "rcrossref", "SuppDists", "tidyr", "tree"))
install.packages("nlme", lib="/usr/lib/R/library")
library("BiocInstaller", lib.loc="/home/R/linux-library/main/site-library")
useDevel()
biocLite()
biocLite()
useDevel()
?useDevel()
ls()
install.packages("RefManageR")
library("BiocInstaller", lib.loc="~/bin/R-devel/lib/R/library")
biocLite()
setwd("~/gitrepos/bootNet")
format(Sys.time(), "%d %B, %Y")
format(Sys.time(), "%dth %B, %Y")
require(glmnet)
citation(glmnet)
citation('glmnet')
